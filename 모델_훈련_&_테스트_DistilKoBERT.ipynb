{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.11"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit (conda)"
    },
    "interpreter": {
      "hash": "c86e0eb5395ede85b9f59b6e8263bc6c22037c4e880f7255165769e612363282"
    },
    "colab": {
      "name": "모델_훈련_&_테스트_DistilKoBERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb16f6e6e5114d97ab3fdd95bb33f0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b41cd5752f054ef18cdda44532db7b6f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cbe035e69a0470fb7cccf669333b96e",
              "IPY_MODEL_3add3703b24040e3b9592aaa518c6d80",
              "IPY_MODEL_2595c6eec34a46668e919039e52f5b7f"
            ]
          }
        },
        "b41cd5752f054ef18cdda44532db7b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cbe035e69a0470fb7cccf669333b96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c40d846a4504e4cbaf7980184f2ad4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Skipping the first batches: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7d4745127d047febf584257bf174e52"
          }
        },
        "3add3703b24040e3b9592aaa518c6d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f6877b76a4844460b1501a19bdcc82fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 452,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 452,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69247a0fbb244916b8e9f47e9f856ef3"
          }
        },
        "2595c6eec34a46668e919039e52f5b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19553af8ca5a482f8ddcb6f4e7794674",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 452/452 [00:02&lt;00:00, 238.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c95cd784eac444b29ac1c233e795a8c9"
          }
        },
        "8c40d846a4504e4cbaf7980184f2ad4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7d4745127d047febf584257bf174e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6877b76a4844460b1501a19bdcc82fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69247a0fbb244916b8e9f47e9f856ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19553af8ca5a482f8ddcb6f4e7794674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c95cd784eac444b29ac1c233e795a8c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c8f971ec41d42f09a7c5c8f5fa47496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f01b18f8d9c4064b38141fba7650af4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_40cff6ccf6a54a4694b45df3b71d3e26",
              "IPY_MODEL_3b4763cc628949adb9464f4b404ab1a1",
              "IPY_MODEL_23d40fc8b1fc454c84980b4452284f33"
            ]
          }
        },
        "2f01b18f8d9c4064b38141fba7650af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40cff6ccf6a54a4694b45df3b71d3e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47ee4a4e7bc54f889eebb12d99ee47b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed07688627c745b58ee269608f62cdea"
          }
        },
        "3b4763cc628949adb9464f4b404ab1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab1df6b073994ca49f18e624d7ec25e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d780f0edd4b44474b416aeda8903dad4"
          }
        },
        "23d40fc8b1fc454c84980b4452284f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_410f5c0472e3471a833795a5198a5380",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5000/5000 [00:31&lt;00:00, 155.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a24104cfafa410d9658e3a4460bda75"
          }
        },
        "47ee4a4e7bc54f889eebb12d99ee47b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed07688627c745b58ee269608f62cdea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab1df6b073994ca49f18e624d7ec25e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d780f0edd4b44474b416aeda8903dad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "410f5c0472e3471a833795a5198a5380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a24104cfafa410d9658e3a4460bda75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVt4sbKO8fNJ"
      },
      "source": [
        "# **Spec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3OGmYtJ8cYD",
        "outputId": "88dbc6a0-b8c5-4f44-d1cf-2ebd5be1de6e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  6 07:42:10 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4jbAlLWFFPI",
        "outputId": "f27c7f4c-0719-4530-e793-475a961361ed"
      },
      "source": [
        "!git clone https://github.com/Team-M1/badwords-classifier-train -b BM # 자기 브랜치 이름으로 변경\n",
        "%cd badwords-classifier-train\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'badwords-classifier-train'...\n",
            "remote: Enumerating objects: 258, done.\u001b[K\n",
            "remote: Counting objects: 100% (258/258), done.\u001b[K\n",
            "remote: Compressing objects: 100% (217/217), done.\u001b[K\n",
            "remote: Total 258 (delta 143), reused 153 (delta 39), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (258/258), 2.95 MiB | 25.39 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n",
            "/content/badwords-classifier-train\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 12.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.10.0+cu102)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.9.0+cu102)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.5.1-py3-none-any.whl (282 kB)\n",
            "\u001b[K     |████████████████████████████████| 282 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 65.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.1.5)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.4.5-py3-none-any.whl (919 kB)\n",
            "\u001b[K     |████████████████████████████████| 919 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting sadice\n",
            "  Downloading sadice-0.1.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.22.2.post1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 51.4 MB/s \n",
            "\u001b[?25hCollecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[K     |████████████████████████████████| 302 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (4.62.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (4.6.4)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (3.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 65.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (21.0)\n",
            "Collecting fsspec>=2021.05.0\n",
            "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 66.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (0.70.12.2)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 5)) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 56.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 6)) (1.15.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 48.3 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r requirements.txt (line 7)) (2.6.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (0.37.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (1.34.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (0.4.5)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (1.39.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->-r requirements.txt (line 11)) (1.4.22)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.1-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 72.7 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.5 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.4.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->-r requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec>=2021.05.0->datasets->-r requirements.txt (line 1)) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 74.1 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 70.4 MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->-r requirements.txt (line 11)) (5.2.2)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.1.2-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 78.3 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 78.0 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->-r requirements.txt (line 11)) (2.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->-r requirements.txt (line 11)) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna->-r requirements.txt (line 11)) (2.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 5)) (7.1.2)\n",
            "Building wheels for collected packages: future, pyperclip\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=ce72bf4c6526c3a9dd81a27b874a00bd76c709337fdf07064e234c662391a25b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=2dadca415f3593c3fd6413f8066c6104b276dc770f0eb9a1e825f5e16b95f56e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built future pyperclip\n",
            "Installing collected packages: multidict, yarl, pyperclip, pbr, colorama, async-timeout, stevedore, pyyaml, Mako, fsspec, cmd2, autopage, aiohttp, xxhash, torchmetrics, tokenizers, sacremoses, pyDeprecate, huggingface-hub, future, colorlog, cmaes, cliff, alembic, transformers, sentencepiece, sadice, pytorch-lightning, optuna, datasets\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed Mako-1.1.5 aiohttp-3.7.4.post0 alembic-1.7.1 async-timeout-3.0.1 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-6.4.1 datasets-1.11.0 fsspec-2021.8.1 future-0.18.2 huggingface-hub-0.0.16 multidict-5.1.0 optuna-2.9.1 pbr-5.6.0 pyDeprecate-0.3.1 pyperclip-1.8.2 pytorch-lightning-1.4.5 pyyaml-5.4.1 sacremoses-0.0.45 sadice-0.1.3 sentencepiece-0.1.96 stevedore-3.4.0 tokenizers-0.10.3 torchmetrics-0.5.1 transformers-4.10.0 xxhash-2.0.2 yarl-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLWyf0UWFJZs",
        "outputId": "ac98b848-688a-4db0-9dc0-42a1580843aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "path_to_drive = \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNYRPnTrM-VG"
      },
      "source": [
        "# 시드 통일하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M42n4ohzMRMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b07845-9a84-44e8-a34e-6508dea87c9e"
      },
      "source": [
        "import torch\n",
        "from transformers import set_seed\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL3guvwcNB6D"
      },
      "source": [
        "# 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHbJrxqGQDW0"
      },
      "source": [
        "# 만약 ForSequenceClassification이 붙은 모델을 사용할 경우\n",
        "model_config = {\n",
        "    \"num_labels\": 3,\n",
        "    \"id2label\": {0: 0, 1: 1, 2: 2},\n",
        "    \"label2id\": {0: 0, 1: 1, 2: 2}\n",
        "}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elGC6r7pNAVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeabea06-3281-4062-9fc5-ced3fc48e7b9"
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "from tokenization_kobert import KoBertTokenizer\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"monologg/distilkobert\", **model_config)\n",
        "tokenizer = KoBertTokenizer.from_pretrained(\"monologg/kobert\", model_max_length=512)\n",
        "\n",
        "# model.save_pretrained(\"./model\")\n",
        "tokenizer.tokenize(\"안녕하세요. 오늘 날씨는 비가 계속 내리내요.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/monologg/distilkobert/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d5d25a119f63fb5526032bb7cdaf522e10cccab75fe0a539eca437722feca3d.0638161d3d5ebe20c18198663a075aca59b59977a233e0ca4b40737067ea8894\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"2\": 2\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.10.0\",\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/monologg/distilkobert/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/2ab3b2e47685f9122f02e6102301f5f4af62b325a61b2823d45a35f2a941e8ee.9c7fd319d48a58dafb6587047bf054e7f7fd4cc3371dcac3b2aef52ed33cb265\n",
            "Some weights of the model checkpoint at monologg/distilkobert were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at monologg/distilkobert and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer_78b3253a26.model from cache at /root/.cache/huggingface/transformers/7e55d7972628e6fc1babc614b5dd8bb43ab4f9d8541adc9fb1851112a7a7c5cc.4d2f4af7c2ca9df5b147978a95d38840e84801a378eee25756b008638e0bdc7f\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/efee434f5f4c5c89b5a7d8d5f30bbb0496f1540349fcfa21729cec5b96cfd2d1.719459e20bc981bc2093e859b02c3a3e51bab724d6b58927b23b512a3981229f\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/d1c07e179f5e00959a3c8e4a150eaa4907dfe26544e4a71f2b0163982a476523.767d1b760a83978bae6c324157fad57ee513af333a7cea6986e852579f6f0dd1\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer.json from cache at None\n",
            "loading configuration file https://huggingface.co/monologg/kobert/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/31dc8da633439f22ed80bede01f337996bc709eb8429f86f2b24e2103558b039.89a06cdfd16840fd89cc5c2493ef63cd0b6068e85f70ac988a3673e2722cab2e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁안', '녕', '하세요', '.', '▁오늘', '▁날씨', '는', '▁비가', '▁계속', '▁내리', '내', '요', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU9PiktAF0S7"
      },
      "source": [
        "# 하이퍼 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJ_aq34FFPM"
      },
      "source": [
        "num_classes = 3\n",
        "\n",
        "# 원하는 대로 고쳐서 사용\n",
        "batch_size = 32\n",
        "lr = 0.0001\n",
        "epochs = 150"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8BzmhrpONuf"
      },
      "source": [
        "# 옵티마이저와 스케줄러\n",
        "# 원하는 대로 고쳐서 사용\n",
        "\n",
        "# from torch.optim import AdamW\n",
        "# from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "# LENGTH_OF_TRAIN_DATA = 40242\n",
        "# num_training_steps = ((LENGTH_OF_TRAIN_DATA - 1) // batch_size + 1) * epochs\n",
        "# optimizer = AdamW(model.parameters(), lr=lr)\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, int(num_training_steps * 0.1), num_training_steps)\n",
        "\n",
        "# 만약 이 스케줄러를 사용할 경우,\n",
        "# optimizer.step() 바로 다음에\n",
        "# scheduler.step()을 호출해야 함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgG45_B6RUJa"
      },
      "source": [
        "# f1 score 계산하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubNHt4R0RTyO"
      },
      "source": [
        "# 1. torchmetrics 사용\n",
        "# requirements에 넣어놨으니 따로 설치할 필요 없음\n",
        "\n",
        "# from torchmetrics import F1\n",
        "\n",
        "\n",
        "# f1_score = F1(num_classes=num_classes)\n",
        "\n",
        "# # 검증 단계에서 사용\n",
        "# for inputs, labels in val_loader:\n",
        "#     # 대충 코드\n",
        "#     output = model(inputs)  # 대충 아웃풋\n",
        "#     pred = torch.argmax(output, dim=1)\n",
        "#     batch_f1 = f1_score(pred, labels)\n",
        "#     print(batch_f1)\n",
        "\n",
        "# f1 = f1_score.compute()\n",
        "# print(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTJAFujHRQ_F"
      },
      "source": [
        "# 2. datasets 사용\n",
        "# requirements에 넣어놨으니 따로 설치할 필요 없음\n",
        "# 3번 사이킷런 사용법 쓰십시오 이건 좋지 않음\n",
        "\n",
        "# from datasets import load_metric\n",
        "\n",
        "\n",
        "# f1_score = load_metric(\"f1\")\n",
        "\n",
        "# for inputs, labels in val_loader:\n",
        "#     # 대충 코드\n",
        "#     output = model(inputs)\n",
        "#     pred = torch.argmax(output, dim=1)\n",
        "#     f1_score.add_batch(predictions=pred, references=labels)\n",
        "\n",
        "# f1 = f1_score.compute()\n",
        "# print(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7TFpRaB1due"
      },
      "source": [
        "# 3. sklearn 사용\n",
        "# from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "# def compute_metrics(p):\n",
        "#     pred, labels = p\n",
        "#     pred = np.argmax(pred, axis=1)\n",
        "\n",
        "#     accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "#     f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "#     return {\"accuracy\": accuracy, \"f1\": f1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJnOaa2LFMh1"
      },
      "source": [
        "# **훈련**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIF65K5QFOLU"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"macro\")\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh-oODGxGt38",
        "outputId": "4dfa8084-3c25-4f0e-9028-2a1d751e3b52"
      },
      "source": [
        "from data_loader import get_data_loaders\n",
        "\n",
        "\n",
        "train_data, val_data, test_data = get_data_loaders(tokenizer, return_loader=False)\n",
        "train_data = train_data.remove_columns(\"token_type_ids\")\n",
        "val_data = val_data.remove_columns(\"token_type_ids\")\n",
        "test_data = test_data.remove_columns(\"token_type_ids\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-2093c11bcee5afac\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-2093c11bcee5afac/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2093c11bcee5afac/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-0fa7aba7f64e24e4.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2093c11bcee5afac/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-7ef3596a625ea82e.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2093c11bcee5afac/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-915f026585d9b140.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1F7tx8iSL0s"
      },
      "source": [
        "model_name = \"DistilKoBERT_without_decay\"\n",
        "save_path = f\"{path_to_drive}/{model_name}\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3EzrRSsHH6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4387a96a-0adf-46d4-9e93-ed3b7c57a122"
      },
      "source": [
        "from transformers import TrainingArguments, EarlyStoppingCallback\n",
        "\n",
        "from trainer import ImbalancedSamplerTrainer\n",
        " \n",
        "\n",
        "# optimizer = AdamW(model.parameters(), lr =1e-4, eps = 1e-8)\n",
        "# num_train_epochs = 150\n",
        "# scheduler = get_polynomial_decay_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_train_epochs)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=save_path,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=1e-05,\n",
        "    logging_dir=save_path + \"/log\", \n",
        "    lr_scheduler_type=\"linear\", # (:obj:`str` or :class:`~transformers.SchedulerType`, `optional`, defaults to :obj:`\"linear\"`):The scheduler type to use. See the documentation of :class:`~transformers.SchedulerType` for all possible values.\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_total_limit = 1,       # Only last 1 models are saved(best model). Older ones are deleted. ref= https://stackoverflow.com/questions/62525680/save-only-best-weights-with-huggingface-transformers\n",
        "    load_best_model_at_end=True,  \n",
        "    num_train_epochs=150,       # total number of training epochs\n",
        "    seed=42,\n",
        "    fp16=True,\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    metric_for_best_model=\"f1\",\n",
        "    per_device_train_batch_size=16,     # batch size per device during training\n",
        "    per_device_eval_batch_size=16,      # batch size for evaluation\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "trainer = ImbalancedSamplerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    # tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=15)],\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 500\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using amp fp16 backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pa07FReNRglk",
        "outputId": "4d155d7a-ad43-4503-e950-588594097a1e"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 40242\n",
            "  Num Epochs = 150\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 377400\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23500' max='377400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 23500/377400 35:29 < 8:54:32, 11.03 it/s, Epoch 9/150]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.201500</td>\n",
              "      <td>0.396620</td>\n",
              "      <td>0.866503</td>\n",
              "      <td>0.670570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.198500</td>\n",
              "      <td>0.452570</td>\n",
              "      <td>0.852639</td>\n",
              "      <td>0.678171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.182700</td>\n",
              "      <td>0.466956</td>\n",
              "      <td>0.861136</td>\n",
              "      <td>0.687340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.176600</td>\n",
              "      <td>0.454417</td>\n",
              "      <td>0.861583</td>\n",
              "      <td>0.669807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>0.429547</td>\n",
              "      <td>0.880590</td>\n",
              "      <td>0.702346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.170800</td>\n",
              "      <td>0.528103</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.659012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.166400</td>\n",
              "      <td>0.496589</td>\n",
              "      <td>0.866055</td>\n",
              "      <td>0.675109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.173500</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>0.877013</td>\n",
              "      <td>0.701208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.159000</td>\n",
              "      <td>0.513188</td>\n",
              "      <td>0.863372</td>\n",
              "      <td>0.672897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.140100</td>\n",
              "      <td>0.437335</td>\n",
              "      <td>0.883945</td>\n",
              "      <td>0.706900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.151900</td>\n",
              "      <td>0.426177</td>\n",
              "      <td>0.885286</td>\n",
              "      <td>0.704015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.151200</td>\n",
              "      <td>0.466618</td>\n",
              "      <td>0.886404</td>\n",
              "      <td>0.704690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.141300</td>\n",
              "      <td>0.451821</td>\n",
              "      <td>0.887075</td>\n",
              "      <td>0.706373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.140700</td>\n",
              "      <td>0.488260</td>\n",
              "      <td>0.886628</td>\n",
              "      <td>0.699327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.141900</td>\n",
              "      <td>0.489536</td>\n",
              "      <td>0.883945</td>\n",
              "      <td>0.700967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.133800</td>\n",
              "      <td>0.499632</td>\n",
              "      <td>0.892442</td>\n",
              "      <td>0.700902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.120300</td>\n",
              "      <td>0.593098</td>\n",
              "      <td>0.874553</td>\n",
              "      <td>0.687154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.136700</td>\n",
              "      <td>0.435436</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>0.728526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.124900</td>\n",
              "      <td>0.524099</td>\n",
              "      <td>0.887299</td>\n",
              "      <td>0.710174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.121500</td>\n",
              "      <td>0.594635</td>\n",
              "      <td>0.876565</td>\n",
              "      <td>0.690430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.130100</td>\n",
              "      <td>0.527023</td>\n",
              "      <td>0.886852</td>\n",
              "      <td>0.701301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.127200</td>\n",
              "      <td>0.537588</td>\n",
              "      <td>0.885063</td>\n",
              "      <td>0.708202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.103800</td>\n",
              "      <td>0.524655</td>\n",
              "      <td>0.892665</td>\n",
              "      <td>0.718425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.117900</td>\n",
              "      <td>0.538536</td>\n",
              "      <td>0.888417</td>\n",
              "      <td>0.711633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.114000</td>\n",
              "      <td>0.534348</td>\n",
              "      <td>0.886628</td>\n",
              "      <td>0.699458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.107500</td>\n",
              "      <td>0.523826</td>\n",
              "      <td>0.902281</td>\n",
              "      <td>0.717978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.114300</td>\n",
              "      <td>0.502942</td>\n",
              "      <td>0.900716</td>\n",
              "      <td>0.725572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.094200</td>\n",
              "      <td>0.511638</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>0.730808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.095400</td>\n",
              "      <td>0.569847</td>\n",
              "      <td>0.896020</td>\n",
              "      <td>0.712842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.103000</td>\n",
              "      <td>0.599203</td>\n",
              "      <td>0.889311</td>\n",
              "      <td>0.712226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.096400</td>\n",
              "      <td>0.516098</td>\n",
              "      <td>0.913014</td>\n",
              "      <td>0.724667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.099600</td>\n",
              "      <td>0.531820</td>\n",
              "      <td>0.910107</td>\n",
              "      <td>0.736713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.535060</td>\n",
              "      <td>0.905635</td>\n",
              "      <td>0.726870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.104800</td>\n",
              "      <td>0.554803</td>\n",
              "      <td>0.896914</td>\n",
              "      <td>0.719383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>0.559312</td>\n",
              "      <td>0.900045</td>\n",
              "      <td>0.726335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.092200</td>\n",
              "      <td>0.609004</td>\n",
              "      <td>0.894902</td>\n",
              "      <td>0.703042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>0.096200</td>\n",
              "      <td>0.626148</td>\n",
              "      <td>0.888417</td>\n",
              "      <td>0.690954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.093800</td>\n",
              "      <td>0.523329</td>\n",
              "      <td>0.912120</td>\n",
              "      <td>0.731604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>0.084000</td>\n",
              "      <td>0.553262</td>\n",
              "      <td>0.904293</td>\n",
              "      <td>0.723640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.079800</td>\n",
              "      <td>0.597043</td>\n",
              "      <td>0.905188</td>\n",
              "      <td>0.724668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>0.092500</td>\n",
              "      <td>0.652001</td>\n",
              "      <td>0.889982</td>\n",
              "      <td>0.695176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.090800</td>\n",
              "      <td>0.555137</td>\n",
              "      <td>0.912791</td>\n",
              "      <td>0.731773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>0.092500</td>\n",
              "      <td>0.602298</td>\n",
              "      <td>0.898479</td>\n",
              "      <td>0.714407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.081700</td>\n",
              "      <td>0.574214</td>\n",
              "      <td>0.906306</td>\n",
              "      <td>0.731581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>0.078900</td>\n",
              "      <td>0.538779</td>\n",
              "      <td>0.915474</td>\n",
              "      <td>0.734431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.098200</td>\n",
              "      <td>0.560689</td>\n",
              "      <td>0.913909</td>\n",
              "      <td>0.731563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>0.079900</td>\n",
              "      <td>0.584284</td>\n",
              "      <td>0.903623</td>\n",
              "      <td>0.727120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7500] due to args.save_total_limit\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8000] due to args.save_total_limit\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-1000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-1000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-1500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-1500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-1500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-2000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-2000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-2000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-2500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-2500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-2500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-1500] due to args.save_total_limit\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-2000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-3000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-3000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-3000/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-3500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-3500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-3500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-3000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-4000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-4000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-4000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-3500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-4500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-4500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-4500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-4000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-5000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-5000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-5000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-2500] due to args.save_total_limit\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-4500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-5500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-5500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-5500/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-5500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-7500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-9000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-9000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-9000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-5000] due to args.save_total_limit\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-9500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-9500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-9500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-10000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-10000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-10000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-9500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-10500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-10500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-10500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-10000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-11000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-11000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-11000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-10500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-11500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-11500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-11500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-11000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-12000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-12000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-12000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-11500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-12500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-12500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-12500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-12000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-13000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-13000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-13000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-12500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-13500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-13500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-13500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-13000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-14000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-14000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-14000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-9000] due to args.save_total_limit\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-13500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-14500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-14500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-14500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-15000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-15000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-15000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-14500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-15500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-15500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-15500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-15000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-14000] due to args.save_total_limit\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-15500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16500/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-17000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-17000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-17000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-17500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-17500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-17500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-17000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-18000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-18000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-18000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-17500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-18500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-18500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-18500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-18000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-19000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-19000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-19000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-18500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-19500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-19500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-19500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-19000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-20000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-20000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-20000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-19500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-20500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-20500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-20500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-20000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-21000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-21000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-21000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-20500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-21500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-21500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-21500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-21000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-22000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-22000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-22000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-21500] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1314: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-22500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-22500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-22500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-22000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-23000\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-23000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-23000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-22500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-23500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-23500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-23500/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-23000] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16000 (score: 0.7367126438786421).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=23500, training_loss=0.12296386621353474, metrics={'train_runtime': 2129.6701, 'train_samples_per_second': 2834.383, 'train_steps_per_second': 177.211, 'total_flos': 2.523916204515533e+16, 'train_loss': 0.12296386621353474, 'epoch': 9.34})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788,
          "referenced_widgets": [
            "fb16f6e6e5114d97ab3fdd95bb33f0a0",
            "b41cd5752f054ef18cdda44532db7b6f",
            "5cbe035e69a0470fb7cccf669333b96e",
            "3add3703b24040e3b9592aaa518c6d80",
            "2595c6eec34a46668e919039e52f5b7f",
            "8c40d846a4504e4cbaf7980184f2ad4d",
            "c7d4745127d047febf584257bf174e52",
            "f6877b76a4844460b1501a19bdcc82fc",
            "69247a0fbb244916b8e9f47e9f856ef3",
            "19553af8ca5a482f8ddcb6f4e7794674",
            "c95cd784eac444b29ac1c233e795a8c9"
          ]
        },
        "id": "Sfqpz8zJMd5G",
        "outputId": "9f2933b5-eac6-4395-f801-99cfb30bcc16"
      },
      "source": [
        "# trainer.train(resume_from_checkpoint=True) # 끊기기전 모델 사용하여 계속 학습 진행"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading model from /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8000).\n",
            "***** Running training *****\n",
            "  Num examples = 40242\n",
            "  Num Epochs = 150\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 377400\n",
            "  Continuing training from checkpoint, will skip to saved global_step\n",
            "  Continuing training from epoch 3\n",
            "  Continuing training from global step 8000\n",
            "  Will skip the first 3 epochs then the first 452 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb16f6e6e5114d97ab3fdd95bb33f0a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/452 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8501' max='377400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  8499/377400 00:30 < 6:21:03, 16.14 it/s, Epoch 3.38/150]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.200600</td>\n",
              "      <td>0.421809</td>\n",
              "      <td>0.863596</td>\n",
              "      <td>0.676681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 4472\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8500\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-8500/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d967356da131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 끊기기전 모델 사용하여 계속 학습 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1591\u001b[0m         \u001b[0;31m# Maybe delete some older checkpoints.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rotate_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_optimizer_and_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_rotate_checkpoints\u001b[0;34m(self, use_mtime, output_dir)\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;31m# Check if we should delete older checkpoint(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m         \u001b[0mcheckpoints_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sorted_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1995\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints_sorted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_total_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_sorted_checkpoints\u001b[0;34m(self, output_dir, checkpoint_prefix, use_mtime)\u001b[0m\n\u001b[1;32m   1982\u001b[0m         \u001b[0;31m# Make sure we don't delete the best model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m             \u001b[0mbest_model_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoints_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoints_sorted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m                 \u001b[0mcheckpoints_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoints_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoints_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoints_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: '/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-6500' is not in list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFo_vlb5MeYJ",
        "outputId": "2a9fef9c-c684-4ec1-eb8e-6dd339194dbe"
      },
      "source": [
        "trainer.save_model(output_dir=save_path)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay\n",
            "Configuration saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmh-3UhxMU2y"
      },
      "source": [
        "# **모델 테스트**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS86Vq8FCYQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a988058-0939-45ec-9a69-7a9f16c90902"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2000.150\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4000.30\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2000.150\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4000.30\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNWbcW0NMkcr",
        "outputId": "cd48dbd0-6769-4381-a663-0f9eee552adb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from tokenization_kobert import KoBertTokenizer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16000\")\n",
        "tokenizer = KoBertTokenizer.from_pretrained(\"monologg/kobert\", model_max_length=512) "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16000/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"monologg/distilkobert\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"2\": 2\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.10.0\",\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16000/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/DistilKoBERT_without_decay/checkpoint-16000.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer_78b3253a26.model from cache at /root/.cache/huggingface/transformers/7e55d7972628e6fc1babc614b5dd8bb43ab4f9d8541adc9fb1851112a7a7c5cc.4d2f4af7c2ca9df5b147978a95d38840e84801a378eee25756b008638e0bdc7f\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/efee434f5f4c5c89b5a7d8d5f30bbb0496f1540349fcfa21729cec5b96cfd2d1.719459e20bc981bc2093e859b02c3a3e51bab724d6b58927b23b512a3981229f\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/d1c07e179f5e00959a3c8e4a150eaa4907dfe26544e4a71f2b0163982a476523.767d1b760a83978bae6c324157fad57ee513af333a7cea6986e852579f6f0dd1\n",
            "loading file https://huggingface.co/monologg/kobert/resolve/main/tokenizer.json from cache at None\n",
            "loading configuration file https://huggingface.co/monologg/kobert/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/31dc8da633439f22ed80bede01f337996bc709eb8429f86f2b24e2103558b039.89a06cdfd16840fd89cc5c2493ef63cd0b6068e85f70ac988a3673e2722cab2e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1paAG7q1NKfG"
      },
      "source": [
        "# 테스트 데이터\n",
        "\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/all_data_v2.csv\")\n",
        "test_data = test_df[\"content\"]\n",
        "test_label = test_df[\"labels\"]\n",
        "\n",
        "speed_test_data = test_data.head(50).tolist()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maI7PbEZNNZy",
        "outputId": "e65f22ad-122b-41fa-e016-61ab9a8c6517"
      },
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()\n",
        "print()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw_s0L5GNPU9",
        "outputId": "7f613552-a15d-45f7-b65e-c7f8cb447240"
      },
      "source": [
        "from data_loader import get_data_loaders\n",
        "\n",
        "\n",
        "_, _, test_dataset = get_data_loaders(tokenizer, return_loader=False, use_imbalanced=False, device=\"cuda\") # DistilKoBERT Dataset\n",
        "\n",
        "# _, _, test_loader = get_data_loaders(tokenizer, use_imbalanced=False, device=\"cuda\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-2093c11bcee5afac\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-2093c11bcee5afac/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2093c11bcee5afac/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-0fa7aba7f64e24e4.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2093c11bcee5afac/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-7ef3596a625ea82e.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-2093c11bcee5afac/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-915f026585d9b140.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB7pYe0yNs4s"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test_dataset = test_dataset.remove_columns(\"token_type_ids\")\n",
        "test_loader = DataLoader(test_dataset)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6c8f971ec41d42f09a7c5c8f5fa47496",
            "2f01b18f8d9c4064b38141fba7650af4",
            "40cff6ccf6a54a4694b45df3b71d3e26",
            "3b4763cc628949adb9464f4b404ab1a1",
            "23d40fc8b1fc454c84980b4452284f33",
            "47ee4a4e7bc54f889eebb12d99ee47b9",
            "ed07688627c745b58ee269608f62cdea",
            "ab1df6b073994ca49f18e624d7ec25e9",
            "d780f0edd4b44474b416aeda8903dad4",
            "410f5c0472e3471a833795a5198a5380",
            "0a24104cfafa410d9658e3a4460bda75"
          ]
        },
        "id": "ypGVoyqyNTan",
        "outputId": "4676bc2a-d5b2-48d6-f08b-39eae81533a0"
      },
      "source": [
        "from torchmetrics import F1\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "f1_score = F1(num_classes=3, average=\"macro\").cuda()\n",
        "# f1\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "pred_array = []\n",
        "labels_data = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        labels = batch.pop(\"labels\")\n",
        "        output = model(**batch)\n",
        "        logits = output.logits\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        f1_score(pred, labels)\n",
        "        pred_list = pred.tolist()\n",
        "        pred_array.append(pred_list[0])\n",
        "        labels_list = labels.tolist()\n",
        "        labels_data.append(labels_list[0])\n",
        "\n",
        "score = f1_score.compute()\n",
        "print(score.item())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8f971ec41d42f09a7c5c8f5fa47496",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8813678026199341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3HJL1DRPZGQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}